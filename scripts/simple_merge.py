#!/usr/bin/env python3

from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from collections import defaultdict
from github import GithubException
from github import Github, Auth
from datetime import datetime
import concurrent.futures
import urllib.parse
import threading
import zoneinfo
import requests
import urllib3
import base64
import json
import re
import os

# -------------------- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï --------------------
LOGS_BY_FILE: dict[int, list[str]] = defaultdict(list)
_LOG_LOCK = threading.Lock()

def log(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å –ª–æ–≥–æ–≤ –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ."""
    with _LOG_LOCK:
        LOGS_BY_FILE[0].append(message)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —á–∞—Å–æ–≤–æ–º—É –ø–æ—è—Å—É –ï–≤—Ä–æ–ø–∞/–ú–æ—Å–∫–≤–∞
zone = zoneinfo.ZoneInfo("Europe/Moscow")
thistime = datetime.now(zone)
offset = thistime.strftime("%H:%M | %d.%m.%Y")

# –ü–æ–ª—É—á–µ–Ω–∏–µ GitHub —Ç–æ–∫–µ–Ω–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
GITHUB_TOKEN = os.environ.get("MY_TOKEN", "")
REPO_NAME = os.environ.get("GITHUB_REPOSITORY", "bywarm/wlrusparser")

if GITHUB_TOKEN:
    g = Github(auth=Auth.Token(GITHUB_TOKEN))
else:
    g = Github()

try:
    REPO = g.get_repo(REPO_NAME)
except Exception as e:
    log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GitHub: {e}")
    REPO = None

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–æ–Ω—Ñ–∏–≥–æ–≤
URLS = [
    "https://raw.githubusercontent.com/zieng2/wl/main/vless_lite.txt",
    "https://raw.githubusercontent.com/zieng2/wl/main/vless_universal.txt"
]

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

CHROME_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/138.0.0.0 Safari/537.36"
)

DEFAULT_MAX_WORKERS = int(os.environ.get("MAX_WORKERS", "10"))

def _build_session(max_pool_size: int) -> requests.Session:
    session = requests.Session()
    adapter = HTTPAdapter(
        pool_connections=max_pool_size,
        pool_maxsize=max_pool_size,
        max_retries=Retry(
            total=2,
            backoff_factor=0.5,
            status_forcelist=(429, 500, 502, 503, 504),
            allowed_methods=("HEAD", "GET", "OPTIONS"),
        ),
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update({"User-Agent": CHROME_UA})
    return session

REQUESTS_SESSION = _build_session(max_pool_size=min(DEFAULT_MAX_WORKERS, len(URLS)))

def fetch_url(url: str, timeout: int = 15, max_attempts: int = 3) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å URL"""
    for attempt in range(1, max_attempts + 1):
        try:
            modified_url = url
            verify = True

            if attempt == 2:
                verify = False
            elif attempt == 3:
                parsed = urllib.parse.urlparse(url)
                if parsed.scheme == "https":
                    modified_url = parsed._replace(scheme="http").geturl()
                verify = False

            response = REQUESTS_SESSION.get(modified_url, timeout=timeout, verify=verify)
            response.raise_for_status()
            return response.text

        except requests.exceptions.RequestException as exc:
            last_exc = exc
            if attempt < max_attempts:
                continue
            log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {str(exc)[:100]}")
            return ""
    
    return ""

def extract_host_port(config: str) -> tuple[str, int] | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
    if not config:
        return None
    
    try:
        # VMESS
        if config.startswith("vmess://"):
            try:
                payload = config[8:]
                rem = len(payload) % 4
                if rem:
                    payload += '=' * (4 - rem)
                
                decoded = base64.b64decode(payload).decode('utf-8', errors='ignore')
                
                if decoded.startswith('{'):
                    j = json.loads(decoded)
                    host = j.get('add') or j.get('host') or j.get('ip')
                    port = j.get('port')
                    
                    if host and port:
                        return str(host), int(port)
            except Exception:
                pass
        
        # VLESS / TROJAN / SS
        patterns = [
            r'@([\w\.-]+):(\d{1,5})',
            r'host=([\w\.-]+).*?port=(\d{1,5})',
            r'address=([\w\.-]+).*?port=(\d{1,5})',
            r'//([\w\.-]+):(\d{1,5})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, config, re.IGNORECASE)
            if match:
                host = match.group(1)
                port = int(match.group(2))
                return host, port
        
        # –ü—Ä—è–º–æ–π IP:PORT
        match = re.search(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d{1,5})', config)
        if match:
            return match.group(1), int(match.group(2))
        
        # –ò—â–µ–º —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –≤ –ª—é–±–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        match = re.search(r'([\w\.-]+):(\d{1,5})', config)
        if match:
            host = match.group(1)
            port = int(match.group(2))
            if len(host) > 1 and ('.' in host or host.replace('.', '').replace('-', '').isalnum()):
                return host, port
                
    except Exception:
        pass
    
    return None

def download_and_process_url(url: str) -> list[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏ —Å –æ–¥–Ω–æ–≥–æ URL"""
    try:
        data = fetch_url(url)
        if not data:
            return []
        
        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ª–∏–ø—à–∏–µ—Å—è –∫–æ–Ω—Ñ–∏–≥–∏
        data = re.sub(r'(vmess|vless|trojan|ss|ssr|tuic|hysteria|hysteria2)://', r'\n\1://', data)
        lines = data.splitlines()
        
        configs = []
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and len(line) > 10:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥
                if any(line.startswith(p) for p in ['vmess://', 'vless://', 'trojan://', 
                                                     'ss://', 'ssr://', 'tuic://', 
                                                     'hysteria://', 'hysteria2://']):
                    configs.append(line)
                # –¢–∞–∫–∂–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ @host:port
                elif '@' in line and ':' in line and line.count(':') >= 2:
                    configs.append(line)
        
        log(f"‚úÖ {url.split('/')[3] if '/' in url else 'unknown'}: {len(configs)} –∫–æ–Ω—Ñ–∏–≥–æ–≤")
        return configs
        
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {url}: {str(e)[:100]}")
        return []

def merge_and_deduplicate(all_configs: list[str]) -> list[str]:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏"""
    if not all_configs:
        return []
    
    seen_full = set()
    seen_hostport = set()
    unique_configs = []
    
    for config in all_configs:
        config = config.strip()
        if not config or config in seen_full:
            continue
        seen_full.add(config)
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ö–æ—Å—Ç—É –∏ –ø–æ—Ä—Ç—É
        host_port = extract_host_port(config)
        if host_port:
            key = f"{host_port[0].lower()}:{host_port[1]}"
            if key in seen_hostport:
                continue
            seen_hostport.add(key)
        
        unique_configs.append(config)
    
    return unique_configs

def save_to_file(configs: list[str], filename: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏ –≤ —Ñ–∞–π–ª"""
    try:
        with open(filename, "w", encoding="utf-8") as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ñ–∞–π–ª–∞
            f.write(f"# –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ (–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(URLS)})\n")
            f.write(f"# –û–±–Ω–æ–≤–ª–µ–Ω–æ: {offset}\n")
            f.write(f"# –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤: {len(configs)}\n")
            f.write("#" * 50 + "\n\n")
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏
            for config in configs:
                f.write(config + "\n")
        
        log(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(configs)} –∫–æ–Ω—Ñ–∏–≥–æ–≤ –≤ {filename}")
        
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filename}: {e}")

def upload_to_github(filename: str, remote_path: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞ GitHub"""
    if not REPO:
        log("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ GitHub (–Ω–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
        return
    
    if not os.path.exists(filename):
        log(f"‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        return
    
    try:
        with open(filename, "r", encoding="utf-8") as f:
            content = f.read()
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            file_in_repo = REPO.get_contents(remote_path)
            current_sha = file_in_repo.sha
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç
            remote_content = file_in_repo.decoded_content.decode("utf-8", errors="replace")
            if remote_content == content:
                log(f"üîÑ –§–∞–π–ª {remote_path} –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è")
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
            REPO.update_file(
                path=remote_path,
                message=f"ü§ñ –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {offset}",
                content=content,
                sha=current_sha
            )
            log(f"‚¨ÜÔ∏è –§–∞–π–ª {remote_path} –æ–±–Ω–æ–≤–ª—ë–Ω –Ω–∞ GitHub")
            
        except GithubException as e:
            if e.status == 404:
                # –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
                REPO.create_file(
                    path=remote_path,
                    message=f"ü§ñ –ü–µ—Ä–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ: {offset}",
                    content=content
                )
                log(f"üÜï –§–∞–π–ª {remote_path} —Å–æ–∑–¥–∞–Ω –Ω–∞ GitHub")
            else:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ GitHub: {e.data.get('message', str(e))}")
                
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞ GitHub: {e}")

def update_readme(total_configs: int):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç README.md —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
    if not REPO:
        log("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README (–Ω–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
        return
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π README
        try:
            readme_file = REPO.get_contents("README.md")
            old_content = readme_file.decoded_content.decode("utf-8")
        except GithubException:
            # –ï—Å–ª–∏ README –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            old_content = "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ VPN\n\n"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ raw-—Ñ–∞–π–ª
        raw_url = f"https://github.com/{REPO_NAME}/raw/main/confs/merged.txt"
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
        new_section = f"""
## üìä –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è

| –§–∞–π–ª | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–æ–Ω—Ñ–∏–≥–æ–≤ | –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è | –î–∞—Ç–∞ |
|------|----------|----------|------------------|------|
| [`merged.txt`]({raw_url}) | –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(URLS)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ | {total_configs} | {offset.split(' \| ')[0]} | {offset.split(' \| ')[1]} |

## üì• –°–∫–∞—á–∞—Ç—å
- [merged.txt]({raw_url}) - –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ

## ‚öôÔ∏è –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
–ö–æ–Ω—Ñ–∏–≥–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å —á–µ—Ä–µ–∑ GitHub Actions.
"""
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å—Ç–∞—Ç—É—Å–∞
        status_pattern = r'## üìä –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è[\s\S]*?(?=## |$)'
        if re.search(status_pattern, old_content):
            new_content = re.sub(status_pattern, new_section.strip(), old_content)
        else:
            new_content = old_content.strip() + "\n\n" + new_section
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
        REPO.update_file(
            path="README.md",
            message=f"üìù –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README: {total_configs} –∫–æ–Ω—Ñ–∏–≥–æ–≤",
            content=new_content,
            sha=readme_file.sha if 'readme_file' in locals() else None
        )
        log("üìù README.md –æ–±–Ω–æ–≤–ª—ë–Ω")
        
    except Exception as e:
        log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è README: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    log("üöÄ –ù–∞—á–∞–ª–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    log(f"üìÖ –í—Ä–µ–º—è: {offset}")
    log(f"üåê –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(URLS)}")
    
    # 1. –°–∫–∞—á–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    log("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤...")
    
    all_configs = []
    max_workers = min(DEFAULT_MAX_WORKERS, len(URLS))
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(download_and_process_url, url): url for url in URLS}
        
        for future in concurrent.futures.as_completed(futures):
            url = futures[future]
            try:
                configs = future.result(timeout=30)
                if configs:
                    all_configs.extend(configs)
            except Exception as e:
                log(f"‚ùå –¢–∞–π–º–∞—É—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ –¥–ª—è {url}: {str(e)[:50]}")
    
    log(f"üìä –°–∫–∞—á–∞–Ω–æ –≤—Å–µ–≥–æ: {len(all_configs)} –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    
    if not all_configs:
        log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞")
        return
    
    # 2. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    log("üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
    unique_configs = merge_and_deduplicate(all_configs)
    log(f"üîÑ –ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(unique_configs)} –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    
    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
    os.makedirs("confs", exist_ok=True)
    output_file = "confs/merged.txt"
    save_to_file(unique_configs, output_file)
    
    # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ GitHub
    log("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ GitHub...")
    upload_to_github(output_file, "confs/merged.txt")
    
    # 5. –û–±–Ω–æ–≤–ª—è–µ–º README
    update_readme(len(unique_configs))
    
    # 6. –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    log("=" * 50)
    log("üìä –ò–¢–û–ì–ò:")
    log(f"   üåê –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(URLS)}")
    log(f"   üì• –°–∫–∞—á–∞–Ω–æ: {len(all_configs)}")
    log(f"   üîÑ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(unique_configs)}")
    log(f"   üìä –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(all_configs) - len(unique_configs)}")
    log(f"   üíæ –§–∞–π–ª: {output_file}")
    log("=" * 50)
    
    # –í—ã–≤–æ–¥–∏–º –ª–æ–≥–∏
    print(f"\nüìã –õ–û–ì–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø ({offset}):")
    print("=" * 50)
    for line in LOGS_BY_FILE[0]:
        print(line)

if __name__ == "__main__":
    main()
