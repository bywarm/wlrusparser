#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π –≤ –ø–æ–ª–µ name
"""

from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from collections import defaultdict
from github import GithubException
from github import Github, Auth
from datetime import datetime
import concurrent.futures
import urllib.parse
import threading
import ipaddress
import zoneinfo
import requests
import urllib3
import base64
import json
import re
import os

# -------------------- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï --------------------
LOGS_BY_FILE: dict[int, list[str]] = defaultdict(list)
_LOG_LOCK = threading.Lock()

def log(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å –ª–æ–≥–æ–≤ –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ."""
    with _LOG_LOCK:
        LOGS_BY_FILE[0].append(message)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —á–∞—Å–æ–≤–æ–º—É –ø–æ—è—Å—É –ï–≤—Ä–æ–ø–∞/–ú–æ—Å–∫–≤–∞
zone = zoneinfo.ZoneInfo("Europe/Moscow")
thistime = datetime.now(zone)
offset = thistime.strftime("%H:%M | %d.%m.%Y")

# –ü–æ–ª—É—á–µ–Ω–∏–µ GitHub —Ç–æ–∫–µ–Ω–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
GITHUB_TOKEN = os.environ.get("MY_TOKEN", "")
REPO_NAME = os.environ.get("GITHUB_REPOSITORY", "bywarm/wlrusparser")

if GITHUB_TOKEN:
    g = Github(auth=Auth.Token(GITHUB_TOKEN))
else:
    g = Github()

try:
    REPO = g.get_repo(REPO_NAME)
except Exception as e:
    log("–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GitHub: " + str(e)[:100])
    REPO = None

# –°–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–¥—Å–µ—Ç–µ–π –¥–ª—è whitelist (–ø–µ—Ä–≤—ã–µ –¥–≤–µ)
WHITELIST_SUBNETS = [
    "95.163.0.0/16",
    "89.208.0.0/16",
    "217.16.0.0/16",
    "5.188.0.0/16",
    "109.120.0.0/16",
    "217.12.0.0/16",
    "176.108.0.0/16",
    "178.154.0.0/16",
    "176.109.0.0/16",
    "176.32.0.0/16",
    "193.53.0.0/16",
    "45.129.0.0/16",
    "37.18.0.0/16",
    "78.159.0.0/16",
    "185.177.0.0/16",
    "45.15.0.0/16",
    "176.122.0.0/16",
    "185.130.0.0/16",
    "37.139.0.0/16",
    "83.166.0.0/16",
    "91.219.0.0/16",
    "51.250.0.0/16",
    "84.201.0.0/16",
    "158.160.0.0/16",
    "130.193.0.0/16"
]
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–¥—Å–µ—Ç–∏ –≤ –æ–±—ä–µ–∫—Ç—ã ipaddress –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
WHITELIST_NETWORKS = [ipaddress.ip_network(subnet) for subnet in WHITELIST_SUBNETS]

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–æ–Ω—Ñ–∏–≥–æ–≤
URLS = [
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/Vless-Reality-White-Lists-Rus-Mobile.txt",
    "https://raw.githubusercontent.com/zieng2/wl/refs/heads/main/vless_universal.txt",
    "https://raw.githubusercontent.com/zieng2/wl/main/vless_lite.txt",
    "https://jsnegsukavsos.hb.ru-msk.vkcloud-storage.ru/love",
    "https://raw.githubusercontent.com/AvenCores/goida-vpn-configs/refs/heads/main/githubmirror/26.txt",
]
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

CHROME_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/138.0.0.0 Safari/537.36"
)

DEFAULT_MAX_WORKERS = int(os.environ.get("MAX_WORKERS", "10"))

def _build_session(max_pool_size: int) -> requests.Session:
    session = requests.Session()
    adapter = HTTPAdapter(
        pool_connections=max_pool_size,
        pool_maxsize=max_pool_size,
        max_retries=Retry(
            total=2,
            backoff_factor=0.5,
            status_forcelist=(429, 500, 502, 503, 504),
            allowed_methods=("HEAD", "GET", "OPTIONS"),
        ),
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update({"User-Agent": CHROME_UA})
    return session

REQUESTS_SESSION = _build_session(max_pool_size=min(DEFAULT_MAX_WORKERS, len(URLS)))

def fetch_url(url: str, timeout: int = 15, max_attempts: int = 3) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å URL"""
    for attempt in range(1, max_attempts + 1):
        try:
            modified_url = url
            verify = True

            if attempt == 2:
                verify = False
            elif attempt == 3:
                parsed = urllib.parse.urlparse(url)
                if parsed.scheme == "https":
                    modified_url = parsed._replace(scheme="http").geturl()
                verify = False

            response = REQUESTS_SESSION.get(modified_url, timeout=timeout, verify=verify)
            response.raise_for_status()
            return response.text

        except requests.exceptions.RequestException as exc:
            last_exc = exc
            if attempt < max_attempts:
                continue
            error_msg = str(exc)
            if len(error_msg) > 100:
                error_msg = error_msg[:100]
            log("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ " + url + ": " + error_msg)
            return ""
    
    return ""

def extract_host_port(config: str) -> tuple[str, int] | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
    if not config:
        return None
    
    try:
        # VMESS
        if config.startswith("vmess://"):
            try:
                payload = config[8:]
                rem = len(payload) % 4
                if rem:
                    payload += '=' * (4 - rem)
                
                decoded = base64.b64decode(payload).decode('utf-8', errors='ignore')
                
                if decoded.startswith('{'):
                    j = json.loads(decoded)
                    host = j.get('add') or j.get('host') or j.get('ip')
                    port = j.get('port')
                    
                    if host and port:
                        return str(host), int(port)
            except Exception:
                pass
        
        # VLESS / TROJAN / SS
        patterns = [
            r'@([\w\.-]+):(\d{1,5})',
            r'host=([\w\.-]+).*?port=(\d{1,5})',
            r'address=([\w\.-]+).*?port=(\d{1,5})',
            r'//([\w\.-]+):(\d{1,5})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, config, re.IGNORECASE)
            if match:
                host = match.group(1)
                port = int(match.group(2))
                return host, port
        
        # –ü—Ä—è–º–æ–π IP:PORT
        match = re.search(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d{1,5})', config)
        if match:
            return match.group(1), int(match.group(2))
        
        # –ò—â–µ–º —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –≤ –ª—é–±–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        match = re.search(r'([\w\.-]+):(\d{1,5})', config)
        if match:
            host = match.group(1)
            port = int(match.group(2))
            if len(host) > 1 and ('.' in host or host.replace('.', '').replace('-', '').isalnum()):
                return host, port
                
    except Exception:
        pass
    
    return None

def is_ip_in_subnets(ip_str: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ IP-–∞–¥—Ä–µ—Å –æ–¥–Ω–æ–π –∏–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –ø–æ–¥—Å–µ—Ç–µ–π"""
    try:
        ip = ipaddress.ip_address(ip_str)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ IPv4
        if ip.version != 4:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ –ª—é–±–æ–π –∏–∑ –ø–æ–¥—Å–µ—Ç–µ–π
        for network in WHITELIST_NETWORKS:
            if ip in network:
                return True
        return False
    except ValueError:
        # –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π IP –∞–¥—Ä–µ—Å
        return False


def download_and_process_url(url: str) -> list[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏ —Å –æ–¥–Ω–æ–≥–æ URL"""
    try:
        data = fetch_url(url)
        if not data:
            return []
        
        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ª–∏–ø—à–∏–µ—Å—è –∫–æ–Ω—Ñ–∏–≥–∏
        data = re.sub(r'(vmess|vless|trojan|ss|ssr|tuic|hysteria|hysteria2)://', r'\n\1://', data)
        lines = data.splitlines()
        
        configs = []
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and len(line) > 10:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥
                if any(line.startswith(p) for p in ['vmess://', 'vless://', 'trojan://', 
                                                     'ss://', 'ssr://', 'tuic://',def add_numbering_to_name(config: str, number: int) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ –≤ –ø–æ–ª–µ name –∫–æ–Ω—Ñ–∏–≥–∞"""
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
        if config.startswith("vmess://"):
            # –î–ª—è VMESS: –ø–∞—Ä—Å–∏–º JSON –∏ –º–µ–Ω—è–µ–º –ø–æ–ª–µ "ps"
            try:
                payload = config[8:]
                rem = len(payload) % 4
                if rem:
                    payload += '=' * (4 - rem)
                
                decoded = base64.b64decode(payload).decode('utf-8', errors='ignore')
                
                if decoded.startswith('{'):
                    j = json.loads(decoded)
                    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π ps
                    existing_ps = j.get('ps', '')
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ ps
                    flag = ""
                    flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_ps)
                    if flag_match:
                        flag = flag_match.group(0) + " "
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
                    new_name = f"{number}. {flag}VMESS | TG: @wlrustg"
                    j['ps'] = new_name
                    
                    # –ö–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
                    new_json = json.dumps(j, separators=(',', ':'))
                    encoded = base64.b64encode(new_json.encode()).decode()
                    return f"vmess://{encoded}"
            except Exception:
                pass
            return config
            
        elif config.startswith("vless://"):
            # –î–ª—è VLESS: –∏–º—è –∑–∞–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ # (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)
            parsed = urllib.parse.urlparse(config)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            existing_fragment = urllib.parse.unquote(parsed.fragment) if parsed.fragment else ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
            flag = ""
            flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_fragment)
            if flag_match:
                flag = flag_match.group(0) + " "
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
            new_name = f"{number}. {flag}VLESS | TG: @wlrustg"
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            new_fragment = urllib.parse.quote(new_name, safe='')
            
            # –°–æ–±–∏—Ä–∞–µ–º URL —Å –Ω–æ–≤—ã–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–º
            new_parsed = parsed._replace(fragment=new_fragment)
            new_config = urllib.parse.urlunparse(new_parsed)
            
            return new_config
            
        elif config.startswith("trojan://"):
            # –î–ª—è Trojan: –∏–º—è —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ
            parsed = urllib.parse.urlparse(config)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            existing_fragment = urllib.parse.unquote(parsed.fragment) if parsed.fragment else ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥
            flag = ""
            flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_fragment)
            if flag_match:
                flag = flag_match.group(0) + " "
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
            new_name = f"{number}. {flag}TROJAN | TG: @wlrustg"
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            new_fragment = urllib.parse.quote(new_name, safe='')
            
            # –°–æ–±–∏—Ä–∞–µ–º URL
            new_parsed = parsed._replace(fragment=new_fragment)
            new_config = urllib.parse.urlunparse(new_parsed)
            
            return new_config
            
        elif config.startswith("ss://"):
            # –î–ª—è SS: –∏–º—è –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ –∏–ª–∏ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
            parsed = urllib.parse.urlparse(config)
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            existing_fragment = urllib.parse.unquote(parsed.fragment) if parsed.fragment else ""
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º query –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            name_from_query = ""
            if not existing_fragment and parsed.query:
                params = urllib.parse.parse_qs(parsed.query)
                if 'name' in params:
                    name_from_query = urllib.parse.unquote(params['name'][0])
            
            existing_name = existing_fragment or name_from_query
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥
            flag = ""
            flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_name)
            if flag_match:
                flag = flag_match.group(0) + " "
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
            new_name = f"{number}. {flag}SS | TG: @wlrustg"
            
            # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            new_fragment = urllib.parse.quote(new_name, safe='')
            
            # –°–æ–±–∏—Ä–∞–µ–º URL
            new_parsed = parsed._replace(fragment=new_fragment)
            new_config = urllib.parse.urlunparse(new_parsed)
            
            return new_config
            
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –ø—ã—Ç–∞–µ–º—Å—è –¥–æ–±–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ # –≤ –∫–æ–Ω–µ—Ü
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            if '#' in config:
                # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç—å –∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                base_part, fragment = config.rsplit('#', 1)
                existing_fragment = urllib.parse.unquote(fragment)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥
                flag = ""
                flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_fragment)
                if flag_match:
                    flag = flag_match.group(0) + " "
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –ø–æ –Ω–∞—á–∞–ª—É
                config_type = "CONFIG"
                if config.startswith("ssr://"):
                    config_type = "SSR"
                elif config.startswith("tuic://"):
                    config_type = "TUIC"
                elif config.startswith("hysteria://"):
                    config_type = "HYSTERIA"
                elif config.startswith("hysteria2://"):
                    config_type = "HYSTERIA2"
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
                new_name = f"{number}. {flag}{config_type} | TG: @wlrustg"
                new_fragment = urllib.parse.quote(new_name, safe='')
                
                return f"{base_part}#{new_fragment}"
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤ –∫–æ–Ω–µ—Ü
                config_type = "CONFIG"
                if config.startswith("ssr://"):
                    config_type = "SSR"
                elif config.startswith("tuic://"):
                    config_type = "TUIC"
                elif config.startswith("hysteria://"):
                    config_type = "HYSTERIA"
                elif config.startswith("hysteria2://"):
                    config_type = "HYSTERIA2"
                
                new_name = f"{number}. {config_type} | TG: @wlrustg"
                new_fragment = urllib.parse.quote(new_name, safe='')
                
                return f"{config}#{new_fragment}"
                
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∫ –∫–æ–Ω—Ñ–∏–≥—É: {str(e)[:100]}")
        return config


def extract_existing_info(config: str) -> tuple:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞: –Ω–æ–º–µ—Ä, —Ñ–ª–∞–≥, –≤–æ—Ç–µ—Ä–º–∞—Ä–∫"""
    config_clean = config.strip()
    
    # –ò—â–µ–º –Ω–æ–º–µ—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ #123, 123., #123.
    number_match = re.search(r'(?:#?\s*)(\d{1,3})(?:\.|\s+|$)', config_clean)
    number = number_match.group(1) if number_match else None
    
    # –ò—â–µ–º —Ñ–ª–∞–≥ —ç–º–æ–¥–∑–∏
    flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', config_clean)
    flag = flag_match.group(0) if flag_match else ""
    
    # –ò—â–µ–º –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ TG: @wlrustg
    tg_match = re.search(r'TG\s*:\s*@wlrustg', config_clean, re.IGNORECASE)
    tg = tg_match.group(0) if tg_match else ""
    
    return number, flag, tg


def process_configs_with_numbering(configs: list[str]) -> list[str]:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ –≤ –ø–æ–ª–µ name –∫–æ–Ω—Ñ–∏–≥–æ–≤"""
    processed_configs = []
    
    for i, config in enumerate(configs, 1):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –Ω—É–º–µ—Ä–∞—Ü–∏—è –∏ –Ω–∞—à –≤–æ—Ç–µ—Ä–º–∞—Ä–∫
        existing_number, _, existing_tg = extract_existing_info(config)
        
        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –Ω–æ–º–µ—Ä –∏ –Ω–∞—à –≤–æ—Ç–µ—Ä–º–∞—Ä–∫, –Ω–µ –º–µ–Ω—è–µ–º
        if existing_number and "TG: @wlrustg" in config:
            processed_configs.append(config)
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
            processed = add_numbering_to_name(config, i)
            processed_configs.append(processed)
    
    return processed_configs 
                                                     'hysteria://', 'hysteria2://']):
                    configs.append(line)
                # –¢–∞–∫–∂–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ @host:port
                elif '@' in line and ':' in line and line.count(':') >= 2:
                    configs.append(line)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–æ—Å–æ–± –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        try:
            repo_name = url.split('/')[3] if '/' in url else 'unknown'
        except:
            repo_name = 'unknown'
        log("‚úÖ " + repo_name + ": " + str(len(configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤")
        return configs
        
    except Exception as e:
        error_msg = str(e)
        if len(error_msg) > 100:
            error_msg = error_msg[:100]
        log("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ " + url + ": " + error_msg)
        return []

def merge_and_deduplicate(all_configs: list[str]) -> tuple[list[str], list[str]]:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ —Å–ø–∏—Å–∫–∞: –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏ whitelist –∫–æ–Ω—Ñ–∏–≥–∏"""
    if not all_configs:
        return [], []
    
    seen_full = set()
    seen_hostport = set()
    unique_configs = []
    whitelist_configs = []
    
    for config in all_configs:
        config = config.strip()
        if not config or config in seen_full:
            continue
        seen_full.add(config)
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ö–æ—Å—Ç—É –∏ –ø–æ—Ä—Ç—É
        host_port = extract_host_port(config)
        if host_port:
            key = host_port[0].lower() + ":" + str(host_port[1])
            if key in seen_hostport:
                continue
            seen_hostport.add(key)
        
        unique_configs.append(config)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ —Ö–æ—Å—Ç –∫ whitelist –ø–æ–¥—Å–µ—Ç—è–º
        if host_port:
            host = host_port[0]
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ IP –∞–¥—Ä–µ—Å
            try:
                ip = ipaddress.ip_address(host)
                if ip.version == 4 and is_ip_in_subnets(str(ip)):
                    whitelist_configs.append(config)
            except ValueError:
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ IP –∞–¥—Ä–µ—Å (–¥–æ–º–µ–Ω–Ω–æ–µ –∏–º—è), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è whitelist
                pass
    
    return unique_configs, whitelist_configs

def process_configs_with_numbering(configs: list[str]) -> list[str]:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ –≤ –ø–æ–ª–µ name –∫–æ–Ω—Ñ–∏–≥–æ–≤"""
    processed_configs = []
    
    for i, config in enumerate(configs, 1):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –Ω—É–º–µ—Ä–∞—Ü–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        existing_number, _, existing_tg, _ = extract_existing_info(config)
        
        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –Ω–æ–º–µ—Ä –∏ –Ω–∞—à –≤–æ—Ç–µ—Ä–º–∞—Ä–∫, –Ω–µ –º–µ–Ω—è–µ–º
        if existing_number and "TG: @wlrustg" in config:
            processed_configs.append(config)
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
            processed = add_numbering_to_name(config, i)
            processed_configs.append(processed)
    
    return processed_configs

def save_to_file(configs: list[str], filename: str, description: str = "", add_numbering: bool = False):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏ –≤ —Ñ–∞–π–ª —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π"""
    try:
        with open(filename, "w", encoding="utf-8") as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ñ–∞–π–ª–∞
            f.write("# " + description + "\n")
            f.write("# –û–±–Ω–æ–≤–ª–µ–Ω–æ: " + offset + "\n")
            f.write("# –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤: " + str(len(configs)) + "\n")
            
            if description == "Whitelist –∫–æ–Ω—Ñ–∏–≥–∏ (—Ç–æ–ª—å–∫–æ –ø–æ–¥—Å–µ—Ç–∏ –∏–∑ —Å–ø–∏—Å–∫–∞)":
                f.write("# –ü–æ–¥—Å–µ—Ç–∏: " + str(len(WHITELIST_SUBNETS)) + "\n")
                f.write("# –í–æ—Ç–µ—Ä–º–∞—Ä–∫: TG: @wlrustg\n")
                f.write("#" * 50 + "\n")
                for subnet in WHITELIST_SUBNETS:
                    f.write("# " + subnet + "\n")
            else:
                f.write("# –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: " + str(len(URLS)) + "\n")
                if add_numbering:
                    f.write("# –í–æ—Ç–µ—Ä–º–∞—Ä–∫: TG: @wlrustg\n")
            
            f.write("#" * 50 + "\n\n")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –Ω—É–º–µ—Ä–∞—Ü–∏–∏
            if add_numbering:
                processed_configs = process_configs_with_numbering(configs)
            else:
                processed_configs = configs
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏
            for config in processed_configs:
                f.write(config + "\n")
        
        log("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ " + str(len(configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤ –≤ " + filename)
        
    except Exception as e:
        log("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ " + filename + ": " + str(e))

def upload_to_github(filename: str, remote_path: str, branch: str = "main"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞ GitHub –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –≤–µ—Ç–∫—É"""
    if not REPO:
        log("–ü—Ä–æ–ø—É—Å–∫–∞—é –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ GitHub (–Ω–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
        return
    
    if not os.path.exists(filename):
        log("–§–∞–π–ª " + filename + " –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        return
    
    try:
        with open(filename, "r", encoding="utf-8") as f:
            content = f.read()
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            file_in_repo = REPO.get_contents(remote_path, ref=branch)
            current_sha = file_in_repo.sha
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç
            remote_content = file_in_repo.decoded_content.decode("utf-8", errors="replace")
            if remote_content == content:
                log(f"–§–∞–π–ª {remote_path} –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è –≤ –≤–µ—Ç–∫–µ {branch}")
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
            REPO.update_file(
                path=remote_path,
                message="ü§ñ –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: " + offset,
                content=content,
                sha=current_sha,
                branch=branch
            )
            log(f"‚¨ÜÔ∏è –§–∞–π–ª {remote_path} –æ–±–Ω–æ–≤–ª—ë–Ω –Ω–∞ GitHub –≤ –≤–µ—Ç–∫–µ {branch}")
            
        except GithubException as e:
            if e.status == 404:
                # –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
                REPO.create_file(
                    path=remote_path,
                    message="ü§ñ –ü–µ—Ä–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ: " + offset,
                    content=content,
                    branch=branch
                )
                log(f"üÜï –§–∞–π–ª {remote_path} —Å–æ–∑–¥–∞–Ω –Ω–∞ GitHub –≤ –≤–µ—Ç–∫–µ {branch}")
            else:
                error_msg = e.data.get('message', str(e))
                log("–û—à–∏–±–∫–∞ GitHub: " + error_msg)
                
    except Exception as e:
        log("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞ GitHub: " + str(e))

def setup_github_pages():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≤–µ—Ç–∫—É gh-pages –¥–ª—è GitHub Pages"""
    if not REPO:
        return False
    
    try:
        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Ç–∫—É gh-pages
        REPO.get_branch("gh-pages")
        return True
    except GithubException:
        try:
            # –°–æ–∑–¥–∞–µ–º –≤–µ—Ç–∫—É gh-pages –Ω–∞ –æ—Å–Ω–æ–≤–µ main
            main_branch = REPO.get_branch("main")
            REPO.create_git_ref(ref="refs/heads/gh-pages", sha=main_branch.commit.sha)
            log("‚úÖ –í–µ—Ç–∫–∞ gh-pages —Å–æ–∑–¥–∞–Ω–∞")
            
            return True
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ—Ç–∫–∏ gh-pages: {str(e)}")
            return False

def update_readme(total_configs: int, wl_configs_count: int):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç README.md —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
    if not REPO:
        log("–ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README (–Ω–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
        return
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π README
        try:
            readme_file = REPO.get_contents("README.md")
            old_content = readme_file.decoded_content.decode("utf-8")
        except GithubException:
            # –ï—Å–ª–∏ README –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            old_content = "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ VPN\n\n"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã
        raw_url_merged = "https://github.com/" + REPO_NAME + "/raw/main/githubmirror/merged.txt"
        raw_url_wl = "https://github.com/" + REPO_NAME + "/raw/main/githubmirror/wl.txt"
        
        # jsDelivr CDN URL
        cdn_url_wl = f"https://cdn.jsdelivr.net/gh/{REPO_NAME}/githubmirror/wl.txt"
        cdn_url_merged = f"https://cdn.jsdelivr.net/gh/{REPO_NAME}/githubmirror/merged.txt"
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –∏ –¥–∞—Ç—É
        time_part = offset.split(" | ")[0]
        date_part = offset.split(" | ")[1] if " | " in offset else ""
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
        new_section = "\n## üìä –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n\n"
        new_section += "| –§–∞–π–ª | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–æ–Ω—Ñ–∏–≥–æ–≤ | –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è | –î–∞—Ç–∞ |\n"
        new_section += "|------|----------|----------|------------------|------|\n"
        new_section += f"| [`merged.txt`]({raw_url_merged}) | –í—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(URLS)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ | {total_configs} | {time_part} | {date_part} |\n"
        new_section += f"| [`wl.txt`]({raw_url_wl}) | –¢–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(WHITELIST_SUBNETS)} –ø–æ–¥—Å–µ—Ç–µ–π | {wl_configs_count} | {time_part} | {date_part} |\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–¥—Å–µ—Ç—è—Ö
        new_section += "## üìã Whitelist –ø–æ–¥—Å–µ—Ç–∏\n"
        new_section += f"–§–∞–π–ª `wl.txt` —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(WHITELIST_SUBNETS)} –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø–æ–¥—Å–µ—Ç–µ–π:\n\n"
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ–¥—Å–µ—Ç–∏ –ø–æ —Å—Ç—Ä–æ–∫–∞–º –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        for i in range(0, len(WHITELIST_SUBNETS), 4):
            subnet_line = WHITELIST_SUBNETS[i:i+4]
            new_section += "`" + "` `".join(subnet_line) + "`  \n"
        
        new_section += "\n## üåê –í–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–∞\n"
        
        new_section += "### –ß–µ—Ä–µ–∑ jsDelivr CDN (–±—ã—Å—Ç—Ä–æ, –∫–µ—à–∏—Ä—É–µ—Ç—Å—è)\n"
        new_section += f"- –í—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏: [{cdn_url_merged}]({cdn_url_merged})\n"
        new_section += f"- –¢–æ–ª—å–∫–æ whitelist: [{cdn_url_wl}]({cdn_url_wl})\n\n"
        
        new_section += "### –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ GitHub\n"
        new_section += f"- –í—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏: [{raw_url_merged}]({raw_url_merged})\n"
        new_section += f"- –¢–æ–ª—å–∫–æ whitelist: [{raw_url_wl}]({raw_url_wl})\n\n"
        
        new_section += "## üîß –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏\n"
        new_section += "‚úÖ **–ù—É–º–µ—Ä–∞—Ü–∏—è –≤ –ø–æ–ª–µ name** - –∫–∞–∂–¥—ã–π –∫–æ–Ω—Ñ–∏–≥ –≤ wl.txt –∏–º–µ–µ—Ç –Ω–æ–º–µ—Ä –ø—Ä—è–º–æ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ name\n"
        new_section += "‚úÖ **–í–æ—Ç–µ—Ä–º–∞—Ä–∫ TG: @wlrustg** - –¥–æ–±–∞–≤–ª–µ–Ω –∫ –∫–∞–∂–¥–æ–º—É –∫–æ–Ω—Ñ–∏–≥—É –≤ –ø–æ–ª–µ name\n"
        new_section += "‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ** - –∫–æ–Ω—Ñ–∏–≥–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å\n"
        new_section += "‚úÖ **–ù–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è** - –µ—Å–ª–∏ –∫–æ–Ω—Ñ–∏–≥ —É–∂–µ –∏–º–µ–µ—Ç –Ω–æ–º–µ—Ä –∏ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫, –æ–Ω–∏ –Ω–µ –¥—É–±–ª–∏—Ä—É—é—Ç—Å—è\n\n"
        
        new_section += "## ‚öôÔ∏è –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ\n"
        new_section += "–ö–æ–Ω—Ñ–∏–≥–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å —á–µ—Ä–µ–∑ GitHub Actions.\n\n"
        
        new_section += "## üì¢ –ö–æ–Ω—Ç–∞–∫—Ç—ã\n"
        new_section += "Telegram –∫–∞–Ω–∞–ª: [@wlrustg](https://t.me/wlrustg)\n"
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å—Ç–∞—Ç—É—Å–∞
        status_pattern = r'## üìä –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è[\s\S]*?(?=## |$)'
        if re.search(status_pattern, old_content):
            new_content = re.sub(status_pattern, new_section.strip(), old_content)
        else:
            new_content = old_content.strip() + "\n\n" + new_section
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
        sha = readme_file.sha if 'readme_file' in locals() else None
        REPO.update_file(
            path="README.md",
            message="üìù –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README: " + str(total_configs) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤, " + str(wl_configs_count) + " –≤ whitelist",
            content=new_content,
            sha=sha
        )
        log("üìù README.md –æ–±–Ω–æ–≤–ª—ë–Ω")
        
    except Exception as e:
        log("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è README: " + str(e))

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    log("üöÄ –ù–∞—á–∞–ª–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    log("üìÖ –í—Ä–µ–º—è: " + offset)
    log("üåê –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: " + str(len(URLS)))
    log("üõ°Ô∏è Whitelist –ø–æ–¥—Å–µ—Ç–µ–π: " + str(len(WHITELIST_SUBNETS)))
    
    # 1. –°–∫–∞—á–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    log("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤...")
    
    all_configs = []
    max_workers = min(DEFAULT_MAX_WORKERS, len(URLS))
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {}
        for url in URLS:
            future = executor.submit(download_and_process_url, url)
            futures[future] = url
        
        for future in concurrent.futures.as_completed(futures):
            url = futures[future]
            try:
                configs = future.result(timeout=30)
                if configs:
                    all_configs.extend(configs)
            except Exception as e:
                error_msg = str(e)
                if len(error_msg) > 50:
                    error_msg = error_msg[:50]
                log("–¢–∞–π–º–∞—É—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ –¥–ª—è " + url + ": " + error_msg)
    
    log("üìä –°–∫–∞—á–∞–Ω–æ –≤—Å–µ–≥–æ: " + str(len(all_configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    
    if not all_configs:
        log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞")
        return
    
    # 2. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ–¥—Å–µ—Ç—è–º
    log("üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è...")
    unique_configs, whitelist_configs = merge_and_deduplicate(all_configs)
    log("üîÑ –ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: " + str(len(unique_configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    log("üõ°Ô∏è Whitelist –∫–æ–Ω—Ñ–∏–≥–æ–≤: " + str(len(whitelist_configs)))
    
    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
    os.makedirs("githubmirror", exist_ok=True)
    output_file_merged = "githubmirror/merged.txt"
    output_file_wl = "githubmirror/wl.txt"
    
    save_to_file(unique_configs, output_file_merged, "–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ (–≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)")
    save_to_file(whitelist_configs, output_file_wl, "Whitelist –∫–æ–Ω—Ñ–∏–≥–∏ (—Ç–æ–ª—å–∫–æ –ø–æ–¥—Å–µ—Ç–∏ –∏–∑ —Å–ø–∏—Å–∫–∞)", add_numbering=True)
    
    # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ GitHub (–æ—Å–Ω–æ–≤–Ω–∞—è –≤–µ—Ç–∫–∞)
    log("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ GitHub (–æ—Å–Ω–æ–≤–Ω–∞—è –≤–µ—Ç–∫–∞)...")
    upload_to_github(output_file_merged, "githubmirror/merged.txt", "main")
    upload_to_github(output_file_wl, "githubmirror/wl.txt", "main")
    
    # 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –≤–µ—Ç–∫—É gh-pages –¥–ª—è GitHub Pages
    log("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –≤–µ—Ç–∫—É gh-pages...")
    if setup_github_pages():
        upload_to_github(output_file_merged, "merged.txt", "gh-pages")
        upload_to_github(output_file_wl, "wl.txt", "gh-pages")
    else:
        log("‚ö†Ô∏è GitHub Pages –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
    
    # 6. –û–±–Ω–æ–≤–ª—è–µ–º README
    update_readme(len(unique_configs), len(whitelist_configs))
    
    # 7. –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    log("=" * 60)
    log("üìä –ò–¢–û–ì–ò:")
    log("   üåê –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: " + str(len(URLS)))
    log("   üì• –°–∫–∞—á–∞–Ω–æ: " + str(len(all_configs)))
    log("   üîÑ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: " + str(len(unique_configs)))
    log("   üìä –î—É–±–ª–∏–∫–∞—Ç–æ–≤: " + str(len(all_configs) - len(unique_configs)))
    log("   üõ°Ô∏è Whitelist: " + str(len(whitelist_configs)))
    log("   üíæ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    log("      ‚Ä¢ githubmirror/merged.txt")
    log("      ‚Ä¢ githubmirror/wl.txt")
    log("=" * 60)
    
    # –í—ã–≤–æ–¥–∏–º –ª–æ–≥–∏
    print("\nüìã –õ–û–ì–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø (" + offset + "):")
    print("=" * 60)
    for line in LOGS_BY_FILE[0]:
        print(line)

if __name__ == "__main__":
    main()
