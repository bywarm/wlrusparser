#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞.
–†–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–µ–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ.
(–µ—Å–ª–∏ –≤—ã –±—É–¥–µ—Ç–µ –ø—Ä–æ–¥–∞–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ –ø–∞—Ä—Å–µ—Ä–∞ - —ç—Ç–æ –±—É–¥–µ—Ç –Ω–∞—Ä—É—à–µ–Ω–∏–µ –ª–∏—Ü–µ–Ω–∑–∏–∏)
–°–∞–º –ø–∞—Ä—Å–µ—Ä —è–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º goida-vpn-configs.
"""

from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from collections import defaultdict
from github import GithubException
from github import Github, Auth
from datetime import datetime
import concurrent.futures
import urllib.parse
import threading
import ipaddress
import zoneinfo
import requests
import urllib3
import calendar
import base64
import json
import re
import os

LOGS_BY_FILE: dict[int, list[str]] = defaultdict(list)
_LOG_LOCK = threading.Lock()

def log(message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å –ª–æ–≥–æ–≤ –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ."""
    with _LOG_LOCK:
        LOGS_BY_FILE[0].append(message)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —á–∞—Å–æ–≤–æ–º—É –ø–æ—è—Å—É –ï–≤—Ä–æ–ø–∞/–ú–æ—Å–∫–≤–∞
zone = zoneinfo.ZoneInfo("Europe/Moscow")
thistime = datetime.now(zone)
offset = thistime.strftime("%H:%M | %d.%m.%Y")

# –ü–æ–ª—É—á–µ–Ω–∏–µ GitHub —Ç–æ–∫–µ–Ω–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
GITHUB_TOKEN = os.environ.get("MY_TOKEN", "")
REPO_NAME = os.environ.get("GITHUB_REPOSITORY", "bywarm/wlrusparser")

if GITHUB_TOKEN:
    g = Github(auth=Auth.Token(GITHUB_TOKEN))
else:
    g = Github()

try:
    REPO = g.get_repo(REPO_NAME)
except Exception as e:
    log("–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GitHub: " + str(e)[:100])
    REPO = None


CONFIG = {
    "output_dir": "githubmirror",          # –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞
    "output_dir_suffix": "",               # –°—É—Ñ—Ñ–∏–∫—Å –ø–∞–ø–∫–∏
    "merged_file": "merged.txt",           # –í—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏
    "wl_file": "wl.txt",                   # Whitelist –∫–æ–Ω—Ñ–∏–≥–∏
    "selected_file": "selected.txt",       # –†—É—á–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã
    "custom_prefix": "wlrus_",             # –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è —Ñ–∞–π–ª–æ–≤
    "use_date_suffix": False,              # –î–æ–±–∞–≤–ª—è—Ç—å –¥–∞—Ç—É –∫ –∏–º–µ–Ω–∞–º?
    "rotate_folders": False,               # –†–æ—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞–ø–∫–∏ –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü?
}


if CONFIG["rotate_folders"]:
    month = datetime.now().month
    year_short = datetime.now().strftime("%y")
    CONFIG["output_dir_suffix"] = f"_{year_short}{month:02d}"

def get_paths():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º"""
    base_dir = CONFIG["output_dir"] + CONFIG["output_dir_suffix"]
    
    # –°—É—Ñ—Ñ–∏–∫—Å –¥–ª—è —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    file_suffix = ""
    if CONFIG["use_date_suffix"]:
        file_suffix = f"_{datetime.now().strftime('%d%m')}"
    
    paths = {
        "base_dir": base_dir,
        "merged": f"{base_dir}/{CONFIG['custom_prefix']}{CONFIG['merged_file'].replace('.txt', '')}{file_suffix}.txt",
        "wl": f"{base_dir}/{CONFIG['custom_prefix']}{CONFIG['wl_file'].replace('.txt', '')}{file_suffix}.txt",
        "selected": f"{base_dir}/{CONFIG['selected_file']}",
        "gh_pages_merged": f"{CONFIG['custom_prefix']}merged{file_suffix}.txt",
        "gh_pages_wl": f"{CONFIG['custom_prefix']}wl{file_suffix}.txt",
    }
    return paths

WHITELIST_SUBNETS = [
    "95.163.0.0/16",
    "89.208.0.0/16",
    "217.16.0.0/16",
    "5.188.0.0/16",
    "109.120.0.0/16",
    "217.12.0.0/16",
    "176.108.0.0/16",
    "178.154.0.0/16",
    "176.109.0.0/16",
    "176.32.0.0/16",
    "193.53.0.0/16",
    "45.129.0.0/16",
    "37.18.0.0/16",
    "78.159.0.0/16",
    "185.177.0.0/16",
    "45.15.0.0/16",
    "176.122.0.0/16",
    "185.130.0.0/16",
    "37.139.0.0/16",
    "83.166.0.0/16",
    "91.219.0.0/16",
    "51.250.0.0/16",
    "84.201.0.0/16",
    "158.160.0.0/16",
    "130.193.0.0/16"
]
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–¥—Å–µ—Ç–∏ –≤ –æ–±—ä–µ–∫—Ç—ã ipaddress –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
WHITELIST_NETWORKS = [ipaddress.ip_network(subnet) for subnet in WHITELIST_SUBNETS]

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–æ–Ω—Ñ–∏–≥–æ–≤
URLS = [
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/Vless-Reality-White-Lists-Rus-Mobile.txt",
    "https://raw.githubusercontent.com/zieng2/wl/refs/heads/main/vless_universal.txt",
    "https://raw.githubusercontent.com/zieng2/wl/main/vless_lite.txt",
    "https://raw.githubusercontent.com/AvenCores/goida-vpn-configs/refs/heads/main/githubmirror/26.txt",
]
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

CHROME_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/138.0.0.0 Safari/537.36"
)

DEFAULT_MAX_WORKERS = int(os.environ.get("MAX_WORKERS", "10"))

def _build_session(max_pool_size: int) -> requests.Session:
    session = requests.Session()
    adapter = HTTPAdapter(
        pool_connections=max_pool_size,
        pool_maxsize=max_pool_size,
        max_retries=Retry(
            total=2,
            backoff_factor=0.5,
            status_forcelist=(429, 500, 502, 503, 504),
            allowed_methods=("HEAD", "GET", "OPTIONS"),
        ),
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    session.headers.update({"User-Agent": CHROME_UA})
    return session

REQUESTS_SESSION = _build_session(max_pool_size=min(DEFAULT_MAX_WORKERS, len(URLS)))

def fetch_url(url: str, timeout: int = 15, max_attempts: int = 3) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å URL"""
    for attempt in range(1, max_attempts + 1):
        try:
            modified_url = url
            verify = True

            if attempt == 2:
                verify = False
            elif attempt == 3:
                parsed = urllib.parse.urlparse(url)
                if parsed.scheme == "https":
                    modified_url = parsed._replace(scheme="http").geturl()
                verify = False

            response = REQUESTS_SESSION.get(modified_url, timeout=timeout, verify=verify)
            response.raise_for_status()
            return response.text

        except requests.exceptions.RequestException as exc:
            last_exc = exc
            if attempt < max_attempts:
                continue
            error_msg = str(exc)
            if len(error_msg) > 100:
                error_msg = error_msg[:100]
            log("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ " + url + ": " + error_msg)
            return ""
    
    return ""

def extract_host_port(config: str) -> tuple[str, int] | None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
    if not config:
        return None
    
    try:
        # VMESS
        if config.startswith("vmess://"):
            try:
                payload = config[8:]
                rem = len(payload) % 4
                if rem:
                    payload += '=' * (4 - rem)
                
                decoded = base64.b64decode(payload).decode('utf-8', errors='ignore')
                
                if decoded.startswith('{'):
                    j = json.loads(decoded)
                    host = j.get('add') or j.get('host') or j.get('ip')
                    port = j.get('port')
                    
                    if host and port:
                        return str(host), int(port)
            except Exception:
                pass
        
        # VLESS / TROJAN / SS
        patterns = [
            r'@([\w\.-]+):(\d{1,5})',
            r'host=([\w\.-]+).*?port=(\d{1,5})',
            r'address=([\w\.-]+).*?port=(\d{1,5})',
            r'//([\w\.-]+):(\d{1,5})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, config, re.IGNORECASE)
            if match:
                host = match.group(1)
                port = int(match.group(2))
                return host, port
        
        # –ü—Ä—è–º–æ–π IP:PORT
        match = re.search(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}):(\d{1,5})', config)
        if match:
            return match.group(1), int(match.group(2))
        
        # –ò—â–µ–º —Ö–æ—Å—Ç –∏ –ø–æ—Ä—Ç –≤ –ª—é–±–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        match = re.search(r'([\w\.-]+):(\d{1,5})', config)
        if match:
            host = match.group(1)
            port = int(match.group(2))
            if len(host) > 1 and ('.' in host or host.replace('.', '').replace('-', '').isalnum()):
                return host, port
                
    except Exception:
        pass
    
    return None

def is_ip_in_subnets(ip_str: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ IP-–∞–¥—Ä–µ—Å –æ–¥–Ω–æ–π –∏–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –ø–æ–¥—Å–µ—Ç–µ–π"""
    try:
        ip = ipaddress.ip_address(ip_str)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ IPv4
        if ip.version != 4:
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ –ª—é–±–æ–π –∏–∑ –ø–æ–¥—Å–µ—Ç–µ–π
        for network in WHITELIST_NETWORKS:
            if ip in network:
                return True
        return False
    except ValueError:
        # –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π IP –∞–¥—Ä–µ—Å
        return False


def download_and_process_url(url: str) -> list[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏ —Å –æ–¥–Ω–æ–≥–æ URL"""
    try:
        data = fetch_url(url)
        if not data:
            return []
        
        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ª–∏–ø—à–∏–µ—Å—è –∫–æ–Ω—Ñ–∏–≥–∏
        data = re.sub(r'(vmess|vless|trojan|ss|ssr|tuic|hysteria|hysteria2)://', r'\n\1://', data)
        lines = data.splitlines()
        
        configs = []
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and len(line) > 10:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥
                if any(line.startswith(p) for p in ['vmess://', 'vless://', 'trojan://', 
                                                     'ss://', 'ssr://', 'tuic://', 
                                                     'hysteria://', 'hysteria2://']):
                    configs.append(line)
                # –¢–∞–∫–∂–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º —Å—Ç—Ä–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ @host:port
                elif '@' in line and ':' in line and line.count(':') >= 2:
                    configs.append(line)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–æ—Å–æ–± –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        try:
            repo_name = url.split('/')[3] if '/' in url else 'unknown'
        except:
            repo_name = 'unknown'
        log("‚úÖ " + repo_name + ": " + str(len(configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤")
        return configs
        
    except Exception as e:
        error_msg = str(e)
        if len(error_msg) > 100:
            error_msg = error_msg[:100]
        log("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ " + url + ": " + error_msg)
        return []
    

def add_numbering_to_name(config: str, number: int) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ –≤ –ø–æ–ª–µ name –∫–æ–Ω—Ñ–∏–≥–∞"""
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
        if config.startswith("vmess://"):
            # –î–ª—è VMESS: –ø–∞—Ä—Å–∏–º JSON –∏ –º–µ–Ω—è–µ–º –ø–æ–ª–µ "ps"
            try:
                payload = config[8:]
                rem = len(payload) % 4
                if rem:
                    payload += '=' * (4 - rem)
                
                decoded = base64.b64decode(payload).decode('utf-8', errors='ignore')
                
                if decoded.startswith('{'):
                    j = json.loads(decoded)
                    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π ps
                    existing_ps = j.get('ps', '')
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ ps
                    flag = ""
                    flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_ps)
                    if flag_match:
                        flag = flag_match.group(0) + " "
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
                    new_name = f"{number}. {flag}VMESS | TG: @wlrustg"
                    j['ps'] = new_name
                    
                    # –ö–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ
                    new_json = json.dumps(j, separators=(',', ':'))
                    encoded = base64.b64encode(new_json.encode()).decode()
                    return f"vmess://{encoded}"
            except Exception:
                pass
            return config
            
        elif config.startswith("vless://"):
            # –î–ª—è VLESS: –∏–º—è –∑–∞–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ # (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)
            parsed = urllib.parse.urlparse(config)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            existing_fragment = urllib.parse.unquote(parsed.fragment) if parsed.fragment else ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
            flag = ""
            flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_fragment)
            if flag_match:
                flag = flag_match.group(0) + " "
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
            new_name = f"{number}. {flag}VLESS | TG: @wlrustg"
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            new_fragment = urllib.parse.quote(new_name, safe='')
            
            # –°–æ–±–∏—Ä–∞–µ–º URL —Å –Ω–æ–≤—ã–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–º
            new_parsed = parsed._replace(fragment=new_fragment)
            new_config = urllib.parse.urlunparse(new_parsed)
            
            return new_config
            
        elif config.startswith("trojan://"):
            # –î–ª—è Trojan: –∏–º—è —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ
            parsed = urllib.parse.urlparse(config)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            existing_fragment = urllib.parse.unquote(parsed.fragment) if parsed.fragment else ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥
            flag = ""
            flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_fragment)
            if flag_match:
                flag = flag_match.group(0) + " "
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
            new_name = f"{number}. {flag}TROJAN | TG: @wlrustg"
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            new_fragment = urllib.parse.quote(new_name, safe='')
            
            # –°–æ–±–∏—Ä–∞–µ–º URL
            new_parsed = parsed._replace(fragment=new_fragment)
            new_config = urllib.parse.urlunparse(new_parsed)
            
            return new_config
            
        elif config.startswith("ss://"):
            # –î–ª—è SS: –∏–º—è –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ –∏–ª–∏ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
            parsed = urllib.parse.urlparse(config)
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            existing_fragment = urllib.parse.unquote(parsed.fragment) if parsed.fragment else ""
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º query –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            name_from_query = ""
            if not existing_fragment and parsed.query:
                params = urllib.parse.parse_qs(parsed.query)
                if 'name' in params:
                    name_from_query = urllib.parse.unquote(params['name'][0])
            
            existing_name = existing_fragment or name_from_query
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥
            flag = ""
            flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_name)
            if flag_match:
                flag = flag_match.group(0) + " "
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
            new_name = f"{number}. {flag}SS | TG: @wlrustg"
            
            # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            new_fragment = urllib.parse.quote(new_name, safe='')
            
            # –°–æ–±–∏—Ä–∞–µ–º URL
            new_parsed = parsed._replace(fragment=new_fragment)
            new_config = urllib.parse.urlunparse(new_parsed)
            
            return new_config
            
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –ø—ã—Ç–∞–µ–º—Å—è –¥–æ–±–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ # –≤ –∫–æ–Ω–µ—Ü
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            if '#' in config:
                # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç—å –∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                base_part, fragment = config.rsplit('#', 1)
                existing_fragment = urllib.parse.unquote(fragment)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–ª–∞–≥
                flag = ""
                flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', existing_fragment)
                if flag_match:
                    flag = flag_match.group(0) + " "
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –ø–æ –Ω–∞—á–∞–ª—É
                config_type = "CONFIG"
                if config.startswith("ssr://"):
                    config_type = "SSR"
                elif config.startswith("tuic://"):
                    config_type = "TUIC"
                elif config.startswith("hysteria://"):
                    config_type = "HYSTERIA"
                elif config.startswith("hysteria2://"):
                    config_type = "HYSTERIA2"
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è
                new_name = f"{number}. {flag}{config_type} | TG: @wlrustg"
                new_fragment = urllib.parse.quote(new_name, safe='')
                
                return f"{base_part}#{new_fragment}"
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤ –∫–æ–Ω–µ—Ü
                config_type = "CONFIG"
                if config.startswith("ssr://"):
                    config_type = "SSR"
                elif config.startswith("tuic://"):
                    config_type = "TUIC"
                elif config.startswith("hysteria://"):
                    config_type = "HYSTERIA"
                elif config.startswith("hysteria2://"):
                    config_type = "HYSTERIA2"
                
                new_name = f"{number}. {config_type} | TG: @wlrustg"
                new_fragment = urllib.parse.quote(new_name, safe='')
                
                return f"{config}#{new_fragment}"
                
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∫ –∫–æ–Ω—Ñ–∏–≥—É: {str(e)[:100]}")
        return config


def extract_existing_info(config: str) -> tuple:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞: –Ω–æ–º–µ—Ä, —Ñ–ª–∞–≥, –≤–æ—Ç–µ—Ä–º–∞—Ä–∫"""
    config_clean = config.strip()
    
    # –ò—â–µ–º –Ω–æ–º–µ—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ #123, 123., #123.
    number_match = re.search(r'(?:#?\s*)(\d{1,3})(?:\.|\s+|$)', config_clean)
    number = number_match.group(1) if number_match else None
    
    # –ò—â–µ–º —Ñ–ª–∞–≥ —ç–º–æ–¥–∑–∏
    flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', config_clean)
    flag = flag_match.group(0) if flag_match else ""
    
    # –ò—â–µ–º –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ TG: @wlrustg
    tg_match = re.search(r'TG\s*:\s*@wlrustg', config_clean, re.IGNORECASE)
    tg = tg_match.group(0) if tg_match else ""
    
    return number, flag, tg


def process_configs_with_numbering(configs: list[str]) -> list[str]:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫ –≤ –ø–æ–ª–µ name –∫–æ–Ω—Ñ–∏–≥–æ–≤"""
    processed_configs = []
    
    for i, config in enumerate(configs, 1):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –Ω—É–º–µ—Ä–∞—Ü–∏—è –∏ –Ω–∞—à –≤–æ—Ç–µ—Ä–º–∞—Ä–∫
        existing_number, _, existing_tg = extract_existing_info(config)
        
        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –Ω–æ–º–µ—Ä –∏ –Ω–∞—à –≤–æ—Ç–µ—Ä–º–∞—Ä–∫, –Ω–µ –º–µ–Ω—è–µ–º
        if existing_number and "TG: @wlrustg" in config:
            processed_configs.append(config)
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é
            processed = add_numbering_to_name(config, i)
            processed_configs.append(processed)
    
    return processed_configs


def merge_and_deduplicate(all_configs: list[str]) -> tuple[list[str], list[str]]:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ —Å–ø–∏—Å–∫–∞: –≤—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏ whitelist –∫–æ–Ω—Ñ–∏–≥–∏"""
    if not all_configs:
        return [], []
    
    seen_full = set()
    seen_hostport = set()
    unique_configs = []
    whitelist_configs = []
    
    for config in all_configs:
        config = config.strip()
        if not config or config in seen_full:
            continue
        seen_full.add(config)
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ö–æ—Å—Ç—É –∏ –ø–æ—Ä—Ç—É
        host_port = extract_host_port(config)
        if host_port:
            key = host_port[0].lower() + ":" + str(host_port[1])
            if key in seen_hostport:
                continue
            seen_hostport.add(key)
        
        unique_configs.append(config)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ —Ö–æ—Å—Ç –∫ whitelist –ø–æ–¥—Å–µ—Ç—è–º
        if host_port:
            host = host_port[0]
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ IP –∞–¥—Ä–µ—Å
            try:
                ip = ipaddress.ip_address(host)
                if ip.version == 4 and is_ip_in_subnets(str(ip)):
                    whitelist_configs.append(config)
            except ValueError:
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ IP –∞–¥—Ä–µ—Å (–¥–æ–º–µ–Ω–Ω–æ–µ –∏–º—è), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è whitelist
                pass
    
    return unique_configs, whitelist_configs


def save_to_file(configs: list[str], file_type: str, description: str = "", add_numbering: bool = False):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥–∏ –≤ —Ñ–∞–π–ª —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –∏–º–µ–Ω–µ–º"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –ø–æ —Ç–∏–ø—É —Ñ–∞–π–ª–∞
    if file_type == "merged":
        filepath = PATHS["merged"]
        filename = os.path.basename(filepath)
    elif file_type == "wl":
        filepath = PATHS["wl"]
        filename = os.path.basename(filepath)
    else:
        filepath = file_type  # –ü—Ä—è–º–æ–π –ø—É—Ç—å
        filename = os.path.basename(filepath)
    
    try:
        os.makedirs(PATHS["base_dir"], exist_ok=True)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# {description}\n")
            f.write(f"# –ü–∞–ø–∫–∞: {PATHS['base_dir']}\n")
            f.write(f"# –§–∞–π–ª: {filename}\n")
            f.write(f"# –û–±–Ω–æ–≤–ª–µ–Ω–æ: {offset}\n")
            f.write(f"# –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤: {len(configs)}\n")
            f.write("#" * 50 + "\n\n")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤
            if add_numbering:
                processed_configs = process_configs_with_numbering(configs)
            else:
                processed_configs = configs
            
            for config in processed_configs:
                f.write(config + "\n")
        
        log(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(configs)} –∫–æ–Ω—Ñ–∏–≥–æ–≤ –≤ {filename}")
        
    except Exception as e:
        log(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filename}: {str(e)}")
        

def upload_to_github(filepath: str, remote_path: str = None, branch: str = "main"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞ GitHub —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –ø—É—Ç—è–º–∏"""
    if not REPO:
        return
    
    if not os.path.exists(filepath):
        log(f"–§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ï—Å–ª–∏ remote_path –Ω–µ —É–∫–∞–∑–∞–Ω, —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    if remote_path is None:
        filename = os.path.basename(filepath)
        remote_path = f"{PATHS['base_dir']}/{filename}"
    
    try:
        with open(filename, "r", encoding="utf-8") as f:
            content = f.read()
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
            file_in_repo = REPO.get_contents(remote_path, ref=branch)
            current_sha = file_in_repo.sha
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç
            remote_content = file_in_repo.decoded_content.decode("utf-8", errors="replace")
            if remote_content == content:
                log(f"–§–∞–π–ª {remote_path} –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è –≤ –≤–µ—Ç–∫–µ {branch}")
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
            REPO.update_file(
                path=remote_path,
                message="ü§ñ –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: " + offset,
                content=content,
                sha=current_sha,
                branch=branch
            )
            log(f"‚¨ÜÔ∏è –§–∞–π–ª {os.path.basename(filepath)} ‚Üí {remote_path} –≤ –≤–µ—Ç–∫–µ {branch}")
            
        except GithubException as e:
            if e.status == 404:
                # –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
                REPO.create_file(
                    path=remote_path,
                    message="ü§ñ –ü–µ—Ä–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ: " + offset,
                    content=content,
                    branch=branch
                )
                log(f"üÜï –§–∞–π–ª {remote_path} —Å–æ–∑–¥–∞–Ω –Ω–∞ GitHub –≤ –≤–µ—Ç–∫–µ {branch}")
            else:
                error_msg = e.data.get('message', str(e))
                log("–û—à–∏–±–∫–∞ GitHub: " + error_msg)
                
    except Exception as e:
        log("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞ GitHub: " + str(e))


def update_readme(total_configs: int, wl_configs_count: int):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç README.md —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
    if not REPO:
        log("–ü—Ä–æ–ø—É—Å–∫–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README (–Ω–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)")
        return
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π README
        try:
            readme_file = REPO.get_contents("README.md")
            old_content = readme_file.decoded_content.decode("utf-8")
        except GithubException:
            # –ï—Å–ª–∏ README –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            old_content = "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ VPN\n\n"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã
        raw_url_merged = "https://github.com/" + REPO_NAME + "/raw/main/githubmirror/merged.txt"
        raw_url_wl = "https://github.com/" + REPO_NAME + "/raw/main/githubmirror/wl.txt"
        raw_url_selected = "https://github.com/" + REPO_NAME + "/raw/main/githubmirror/selected.txt"
        
        
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –∏ –¥–∞—Ç—É
        time_part = offset.split(" | ")[0]
        date_part = offset.split(" | ")[1] if " | " in offset else ""
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
        new_section = "\n## üìä –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n\n"
        new_section += "| –§–∞–π–ª | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–æ–Ω—Ñ–∏–≥–æ–≤ | –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è | –î–∞—Ç–∞ |\n"
        new_section += "|------|----------|----------|------------------|------|\n"
        new_section += f"| [`merged.txt`]({raw_url_merged}) | –í—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(URLS)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ | {total_configs} | {time_part} | {date_part} |\n"
        new_section += f"| [`wl.txt`]({raw_url_wl}) | –¢–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(WHITELIST_SUBNETS)} –ø–æ–¥—Å–µ—Ç–µ–π | {wl_configs_count} | {time_part} | {date_part} |\n"
        new_section += f"| [`selected.txt`]({raw_url_selected}) | –û—Ç–±–æ—Ä–Ω—ã–µ –∞–¥–º–∏–Ω–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥–∏, —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–∏—Å–æ–∫ | –Ω–µ –∑–Ω–∞—é | {time_part} | {date_part} |\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–¥—Å–µ—Ç—è—Ö
        new_section += "## üìã Whitelist –ø–æ–¥—Å–µ—Ç–∏\n"
        new_section += f"–§–∞–π–ª `wl.txt` —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ {len(WHITELIST_SUBNETS)} –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø–æ–¥—Å–µ—Ç–µ–π:\n\n"
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ–¥—Å–µ—Ç–∏ –ø–æ —Å—Ç—Ä–æ–∫–∞–º –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        for i in range(0, len(WHITELIST_SUBNETS), 4):
            subnet_line = WHITELIST_SUBNETS[i:i+4]
            new_section += "`" + "` `".join(subnet_line) + "`  \n"
        
        new_section += "\n## üåê –í–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–∞\n"
        
        
        new_section += "### –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ GitHub\n"
        new_section += f"- –í—Å–µ –∫–æ–Ω—Ñ–∏–≥–∏: [{raw_url_merged}]({raw_url_merged})\n"
        new_section += f"- –¢–æ–ª—å–∫–æ whitelist: [{raw_url_wl}]({raw_url_wl})\n\n"
        
        
        new_section += "## ‚öôÔ∏è –ê–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ\n"
        new_section += "–ö–æ–Ω—Ñ–∏–≥–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å —á–µ—Ä–µ–∑ GitHub Actions.\n\n"
        
        new_section += "## üì¢ –ö–æ–Ω—Ç–∞–∫—Ç—ã\n"
        new_section += "Telegram –∫–∞–Ω–∞–ª: [@wlrustg](https://t.me/wlrustg)\n"
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å—Ç–∞—Ç—É—Å–∞
        status_pattern = r'## üìä –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è[\s\S]*?(?=## |$)'
        if re.search(status_pattern, old_content):
            new_content = re.sub(status_pattern, new_section.strip(), old_content)
        else:
            new_content = old_content.strip() + "\n\n" + new_section
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
        sha = readme_file.sha if 'readme_file' in locals() else None
        REPO.update_file(
            path="README.md",
            message="üìù –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README: " + str(total_configs) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤, " + str(wl_configs_count) + " –≤ whitelist",
            content=new_content,
            sha=sha
        )
        log("üìù README.md –æ–±–Ω–æ–≤–ª—ë–Ω")
        
    except Exception as e:
        log("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è README: " + str(e))

def process_selected_file():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª selected.txt —Å —Ä—É—á–Ω—ã–º–∏ —Å–µ—Ä–≤–µ—Ä–∞–º–∏, –≤–∫–ª—é—á–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é"""
    selected_file = PATHS["selected"]
    
    if os.path.exists(selected_file):
        try:
            with open(selected_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
            
            configs = []
            manual_comments = []  # –¢–æ–ª—å–∫–æ —Ä—É—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏
            skip_auto_header = False
            for line in lines:
                stripped = line.strip()
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                if stripped.startswith("#profile-title: WL RUS (selected)"):
                    skip_auto_header = True
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                if skip_auto_header:
                    if stripped.startswith("#") or not stripped:
                        continue
                    else:
                        skip_auto_header = False
                
                # –¢–µ–ø–µ—Ä—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ã—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                if not stripped:
                    if manual_comments and manual_comments[-1] != "":
                        manual_comments.append("")
                elif stripped.startswith('#'):
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä—É—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                    if not any(stripped.startswith(p) for p in [
                        "#profile-title:", 
                        "#profile-update-interval:", 
                        "#announce:",
                        "# –û–±–Ω–æ–≤–ª–µ–Ω–æ:",
                        "# –í—Å–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–æ–≤:",
                        "# –í–æ—Ç–µ—Ä–º–∞—Ä–∫:",
                        "##################################################"
                    ]):
                        manual_comments.append(stripped)
                else:
                    # –≠—Ç–æ –∫–æ–Ω—Ñ–∏–≥
                    if any(stripped.startswith(p) for p in ['vmess://', 'vless://', 'trojan://', 
                                                             'ss://', 'ssr://', 'tuic://', 
                                                             'hysteria://', 'hysteria2://']):
                        configs.append((len(configs), stripped))
                    elif '@' in stripped and ':' in stripped and stripped.count(':') >= 2:
                        configs.append((len(configs), stripped))
            
            if configs:
                # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
                config_indices = [idx for idx, _ in configs]
                raw_configs = [config for _, config in configs]
                
                seen_full = set()
                seen_hostport = set()
                unique_configs_with_index = []
                
                for idx, config in zip(config_indices, raw_configs):
                    if config in seen_full:
                        continue
                    seen_full.add(config)
                    
                    host_port = extract_host_port(config)
                    if host_port:
                        key = host_port[0].lower() + ":" + str(host_port[1])
                        if key in seen_hostport:
                            continue
                        seen_hostport.add(key)
                    
                    unique_configs_with_index.append((idx, config))
                
                duplicates_count = len(configs) - len(unique_configs_with_index)
                if duplicates_count > 0:
                    log(f"üîç –ù–∞–π–¥–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ selected.txt")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏ —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π
                unique_configs = [config for _, config in unique_configs_with_index]
                processed_configs = process_configs_with_numbering(unique_configs)
                
                processed_by_index = {}
                for (idx, _), processed in zip(unique_configs_with_index, processed_configs):
                    processed_by_index[idx] = processed
                
         
        
        with open(selected_file, "w", encoding="utf-8") as f:
            f.write(f"#profile-title: WL RUS (selected)\n")
            f.write(f"#profile-update-interval: 1\n")
            f.write("#announce: –°–µ—Ä–≤–µ—Ä–∞ –∏–∑ –ø–æ–¥–ø–∏—Å–∫–∏ –¥–æ–ª–∂–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¢–û–õ–¨–ö–û –ø—Ä–∏ –±–µ–ª—ã—Ö —Å–ø–∏—Å–∫–∞—Ö!\n")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä—É—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    if manual_comments:
                        f.write("\n")
                        for comment in manual_comments:
                            if comment == "":
                                f.write("\n")
                            else:
                                f.write(comment + "\n")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥–∏
                    if processed_configs:
                        if manual_comments:
                            f.write("\n")
                        
                        for i in range(len(processed_configs)):
                            if i in processed_by_index:
                                f.write(processed_by_index[i] + "\n")
                                if i < len(processed_configs) - 1:
                                    f.write("\n")
                
                log(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω selected.txt: {len(processed_configs)} –∫–æ–Ω—Ñ–∏–≥–æ–≤ (—É–¥–∞–ª–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)")
                return processed_configs
            else:
                log("‚ÑπÔ∏è –í selected.txt –Ω–µ—Ç –∫–æ–Ω—Ñ–∏–≥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return []
                
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ selected.txt: {str(e)}")
            return []
    else:
        log("‚ÑπÔ∏è –§–∞–π–ª selected.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return []

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
log("üöÄ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–ø—É—Å–∫–∞:")
    log(f"   üìÅ –ü–∞–ø–∫–∞: {PATHS['base_dir']}")
    log(f"   üìÑ Merged: {PATHS['merged'].replace(PATHS['base_dir']+'/', '')}")
    log(f"   üõ°Ô∏è Whitelist: {PATHS['wl'].replace(PATHS['base_dir']+'/', '')}")
    log(f"   üîß Selected: {PATHS['selected'].replace(PATHS['base_dir']+'/', '')}")

    log("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤...")
    
    all_configs = []
    max_workers = min(DEFAULT_MAX_WORKERS, len(URLS))
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {}
        for url in URLS:
            future = executor.submit(download_and_process_url, url)
            futures[future] = url
        
        for future in concurrent.futures.as_completed(futures):
            url = futures[future]
            try:
                configs = future.result(timeout=30)
                if configs:
                    all_configs.extend(configs)
            except Exception as e:
                error_msg = str(e)
                if len(error_msg) > 50:
                    error_msg = error_msg[:50]
                log("–¢–∞–π–º–∞—É—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ –¥–ª—è " + url + ": " + error_msg)
    
    log("üìä –°–∫–∞—á–∞–Ω–æ –≤—Å–µ–≥–æ: " + str(len(all_configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    
    # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º selected.txt (—Ä—É—á–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã)
    log("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ selected.txt...")
    selected_configs = process_selected_file()
    
    
    if not all_configs:
        log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞")
        return
    
    # 4. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ–¥—Å–µ—Ç—è–º
    log("üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è...")
    unique_configs, whitelist_configs = merge_and_deduplicate(all_configs)
    log("üîÑ –ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: " + str(len(unique_configs)) + " –∫–æ–Ω—Ñ–∏–≥–æ–≤")
    log("üõ°Ô∏è Whitelist –∫–æ–Ω—Ñ–∏–≥–æ–≤: " + str(len(whitelist_configs)))
    
    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
    os.makedirs("githubmirror", exist_ok=True)
    output_file_merged = "githubmirror/merged.txt"
    output_file_wl = "githubmirror/wl.txt"
    
    # –°–û–•–†–ê–ù–Ø–ï–ú merged.txt –° –ù–£–ú–ï–†–ê–¶–ò–ï–ô (–≤–∫–ª—é—á–∞—è –∫–æ–Ω—Ñ–∏–≥–∏ –∏–∑ selected.txt)
    save_to_file(unique_configs, "merged", "–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏", add_numbering=True)
    save_to_file(whitelist_configs, "wl", "Whitelist –∫–æ–Ω—Ñ–∏–≥–∏", add_numbering=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ GitHub
    upload_to_github(PATHS["merged"])
    upload_to_github(PATHS["wl"])
    upload_to_github(PATHS["selected"])
    
   # –ó–∞–≥—Ä—É–∂–∞–µ–º selected.txt –Ω–∞ GitHub, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
   # selected_file = "githubmirror/selected.txt"
   # if os.path.exists(selected_file):
   #     upload_to_github(selected_file, "githubmirror/selected.txt", "main")
    
    
    # 8. –û–±–Ω–æ–≤–ª—è–µ–º README
    update_readme(len(unique_configs), len(whitelist_configs))
    
    # 9. –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    log("=" * 60)
    log("üìä –ò–¢–û–ì–ò:")
    log("   üåê –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: " + str(len(URLS)))
    log("   üì• –°–∫–∞—á–∞–Ω–æ –∏–∑ URL: " + str(len(all_configs) - len(selected_configs)))
    log("   üîß –ò–∑ selected.txt: " + str(len(selected_configs)))
    log("   üîÑ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: " + str(len(unique_configs)))
    total_duplicates = (len(all_configs) - len(selected_configs)) + len(selected_configs) - len(unique_configs)
    log("   üìä –î—É–±–ª–∏–∫–∞—Ç–æ–≤: " + str(total_duplicates))
    log("   üõ°Ô∏è Whitelist: " + str(len(whitelist_configs)))
    log("   üíæ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    log("      ‚Ä¢ githubmirror/merged.txt (—Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π)")
    log("      ‚Ä¢ githubmirror/wl.txt (—Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π)")
    log("      ‚Ä¢ githubmirror/selected.txt (–¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω)")
    log("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è GitHub Actions
    log("üíæ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π...")
    log(f"üìä –ö–æ–Ω—Ñ–∏–≥–æ–≤ –≤ merged.txt: {len(unique_configs)}")
    log(f"üõ°Ô∏è –ö–æ–Ω—Ñ–∏–≥–æ–≤ –≤ wl.txt: {len(whitelist_configs)}")
    
    # –í—ã–≤–æ–¥–∏–º –ª–æ–≥–∏
    print("\nüìã –õ–û–ì–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø (" + offset + "):")
    print("=" * 60)
    for line in LOGS_BY_FILE[0]:
        print(line)


if __name__ == "__main__":
    main()
